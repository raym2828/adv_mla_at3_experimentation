{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /Users/tj/Library/Caches/pypoetry/virtualenvs/adv-mla-at3-experimentation-iSAKc5_x-py3.12/lib/python3.12/site-packages (18.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile \n",
    "import io\n",
    "import os\n",
    "import concurrent.futures\n",
    "import time\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow\n",
    "import json\n",
    "from matplotlib.ticker import FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('../advmla_at3_package'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_feather('../data/processed/train_data.feather')\n",
    "df_test = pd.read_feather('../data/processed/test_data.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5106602, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>searchDate</th>\n",
       "      <th>flightDate</th>\n",
       "      <th>startingAirport</th>\n",
       "      <th>destinationAirport</th>\n",
       "      <th>isNonStop</th>\n",
       "      <th>totalFare</th>\n",
       "      <th>totalTravelDistance</th>\n",
       "      <th>segmentsArrivalAirportCode</th>\n",
       "      <th>DepartureTimeHour</th>\n",
       "      <th>CabinCode</th>\n",
       "      <th>AirlineNameScore</th>\n",
       "      <th>date_diff_days</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3767896</th>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>2022-05-06</td>\n",
       "      <td>LGA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>True</td>\n",
       "      <td>93.599998</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>DFW</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929418</th>\n",
       "      <td>2022-05-11</td>\n",
       "      <td>2022-05-18</td>\n",
       "      <td>BOS</td>\n",
       "      <td>IAD</td>\n",
       "      <td>False</td>\n",
       "      <td>207.600006</td>\n",
       "      <td>406.0</td>\n",
       "      <td>JFK||IAD</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5456598</th>\n",
       "      <td>2022-05-08</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>ORD</td>\n",
       "      <td>EWR</td>\n",
       "      <td>False</td>\n",
       "      <td>358.600006</td>\n",
       "      <td>725.0</td>\n",
       "      <td>DTW||EWR</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4876708</th>\n",
       "      <td>2022-05-08</td>\n",
       "      <td>2022-05-18</td>\n",
       "      <td>OAK</td>\n",
       "      <td>BOS</td>\n",
       "      <td>False</td>\n",
       "      <td>728.599976</td>\n",
       "      <td>2688.0</td>\n",
       "      <td>SLC||BOS</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004101</th>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>DFW</td>\n",
       "      <td>ATL</td>\n",
       "      <td>True</td>\n",
       "      <td>228.600006</td>\n",
       "      <td>725.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057863</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>BOS</td>\n",
       "      <td>PHL</td>\n",
       "      <td>True</td>\n",
       "      <td>93.599998</td>\n",
       "      <td>280.0</td>\n",
       "      <td>PHL</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96461</th>\n",
       "      <td>2022-05-07</td>\n",
       "      <td>2022-05-17</td>\n",
       "      <td>ATL</td>\n",
       "      <td>EWR</td>\n",
       "      <td>True</td>\n",
       "      <td>213.600006</td>\n",
       "      <td>762.0</td>\n",
       "      <td>EWR</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565752</th>\n",
       "      <td>2022-05-02</td>\n",
       "      <td>2022-06-09</td>\n",
       "      <td>PHL</td>\n",
       "      <td>ORD</td>\n",
       "      <td>False</td>\n",
       "      <td>339.579987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MCO||ORD</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455243</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>MIA</td>\n",
       "      <td>LGA</td>\n",
       "      <td>True</td>\n",
       "      <td>140.600006</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553263</th>\n",
       "      <td>2022-05-05</td>\n",
       "      <td>2022-05-15</td>\n",
       "      <td>LAX</td>\n",
       "      <td>PHL</td>\n",
       "      <td>False</td>\n",
       "      <td>821.590027</td>\n",
       "      <td>3335.0</td>\n",
       "      <td>FLL||PHL</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        searchDate flightDate startingAirport destinationAirport  isNonStop  \\\n",
       "3767896 2022-04-18 2022-05-06             LGA                DFW       True   \n",
       "929418  2022-05-11 2022-05-18             BOS                IAD      False   \n",
       "5456598 2022-05-08 2022-06-21             ORD                EWR      False   \n",
       "4876708 2022-05-08 2022-05-18             OAK                BOS      False   \n",
       "2004101 2022-05-12 2022-07-01             DFW                ATL       True   \n",
       "1057863 2022-05-09 2022-06-29             BOS                PHL       True   \n",
       "96461   2022-05-07 2022-05-17             ATL                EWR       True   \n",
       "5565752 2022-05-02 2022-06-09             PHL                ORD      False   \n",
       "4455243 2022-05-09 2022-06-15             MIA                LGA       True   \n",
       "3553263 2022-05-05 2022-05-15             LAX                PHL      False   \n",
       "\n",
       "          totalFare  totalTravelDistance segmentsArrivalAirportCode  \\\n",
       "3767896   93.599998               1380.0                        DFW   \n",
       "929418   207.600006                406.0                   JFK||IAD   \n",
       "5456598  358.600006                725.0                   DTW||EWR   \n",
       "4876708  728.599976               2688.0                   SLC||BOS   \n",
       "2004101  228.600006                725.0                        ATL   \n",
       "1057863   93.599998                280.0                        PHL   \n",
       "96461    213.600006                762.0                        EWR   \n",
       "5565752  339.579987                  NaN                   MCO||ORD   \n",
       "4455243  140.600006               1104.0                        LGA   \n",
       "3553263  821.590027               3335.0                   FLL||PHL   \n",
       "\n",
       "         DepartureTimeHour  CabinCode  AirlineNameScore  date_diff_days  \\\n",
       "3767896                  8        1.0                 2              18   \n",
       "929418                  11        1.0                 4               7   \n",
       "5456598                 14        1.0                 4              44   \n",
       "4876708                 17        1.0                 4              10   \n",
       "2004101                 19        1.0                 4              50   \n",
       "1057863                 11        1.0                 4              51   \n",
       "96461                   17        1.0                 4              10   \n",
       "5565752                  7        1.0                 1              38   \n",
       "4455243                 12        1.0                 4              37   \n",
       "3553263                 10        1.0                 2              10   \n",
       "\n",
       "         weekday  \n",
       "3767896        4  \n",
       "929418         2  \n",
       "5456598        1  \n",
       "4876708        2  \n",
       "2004101        4  \n",
       "1057863        2  \n",
       "96461          1  \n",
       "5565752        3  \n",
       "4455243        2  \n",
       "3553263        6  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "searchDate                         0\n",
       "flightDate                         0\n",
       "startingAirport                    0\n",
       "destinationAirport                 0\n",
       "isNonStop                          0\n",
       "totalFare                          0\n",
       "totalTravelDistance           484110\n",
       "segmentsArrivalAirportCode         0\n",
       "DepartureTimeHour                  0\n",
       "CabinCode                          0\n",
       "AirlineNameScore                   0\n",
       "date_diff_days                     0\n",
       "weekday                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "searchDate                         0\n",
       "flightDate                         0\n",
       "startingAirport                    0\n",
       "destinationAirport                 0\n",
       "isNonStop                          0\n",
       "totalFare                          0\n",
       "totalTravelDistance           120986\n",
       "segmentsArrivalAirportCode         0\n",
       "DepartureTimeHour                  0\n",
       "CabinCode                          0\n",
       "AirlineNameScore                   0\n",
       "date_diff_days                     0\n",
       "weekday                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engineering.clean_master import preprocessing_data\n",
    "\n",
    "df_train_processed, df_test_precessed = preprocessing_data(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['date_diff_days', 'weekday', 'CabinCode', 'DepartureTimeHour', 'totalTravelDistance']\n",
    "categorical_features = ['startingAirport', 'destinationAirport', 'isNonStop']\n",
    "target = 'totalFare'\n",
    "\n",
    "df_filtered_train = df_train_processed[categorical_features + selected_features + [target]]\n",
    "df_filtered_test = df_test_precessed[categorical_features + selected_features + [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "numerical_features = ['totalTravelDistance']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one-hot', OneHotEncoder(handle_unknown='ignore'), categorical_features),  \n",
    "        ('scaler', StandardScaler(), numerical_features) \n",
    "    ],\n",
    "    remainder='passthrough')\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression()) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the datasets\n",
    "train_df, val_df = train_test_split(df_filtered_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = train_df.drop(columns=[target], axis=1)  \n",
    "y_train = train_df[target]\n",
    "\n",
    "X_val = val_df.drop(columns=[target], axis=1)  \n",
    "y_val = val_df[target]\n",
    "\n",
    "X_test = df_filtered_test.drop(columns=[target], axis=1)  \n",
    "y_test = df_filtered_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling.null import NullRegressor\n",
    "\n",
    "base_model = NullRegressor()\n",
    "\n",
    "y_base = base_model.fit_predict(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training: 190.866455078125\n",
      "MAE Training: 136.70587158203125\n",
      "RMSE Validation: 189.75318908691406\n",
      "MAE Validation: 136.62557983398438\n",
      "RMSE Testing: 191.07180786132812\n",
      "MAE Testing: 136.75062561035156\n"
     ]
    }
   ],
   "source": [
    "# Baseline result\n",
    "\n",
    "from modeling.performance import print_regressor_scores\n",
    "\n",
    "print_regressor_scores(y_preds=y_base, y_actuals=y_train, set_name='Training')\n",
    "print_regressor_scores(y_preds=base_model.predict(y_val), y_actuals=y_val, set_name='Validation')\n",
    "print_regressor_scores(y_preds=base_model.predict(y_test), y_actuals=y_test, set_name='Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_preds = pipeline.predict(X_train)\n",
    "y_val_preds = pipeline.predict(X_val)\n",
    "y_test_preds = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training: 136.07393438739464\n",
      "MAE Training: 96.59250108703283\n",
      "RMSE Validation: 135.21356822677274\n",
      "MAE Validation: 96.54232007646003\n",
      "RMSE Testing: 135.8049850296426\n",
      "MAE Testing: 96.63959049758105\n"
     ]
    }
   ],
   "source": [
    "print_regressor_scores(y_preds, y_train, set_name='Training')\n",
    "print_regressor_scores(y_val_preds, y_actuals=y_val, set_name='Validation')\n",
    "print_regressor_scores(y_test_preds, y_actuals=y_test, set_name='Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linear_model.joblib']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "model_path = 'linear_model.joblib'\n",
    "joblib.dump(pipeline, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /Users/tj/Library/Caches/pypoetry/virtualenvs/adv-mla-at3-experimentation-iSAKc5_x-py3.12/lib/python3.12/site-packages (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/tj/Library/Caches/pypoetry/virtualenvs/adv-mla-at3-experimentation-iSAKc5_x-py3.12/lib/python3.12/site-packages (from lightgbm) (2.1.2)\n",
      "Requirement already satisfied: scipy in /Users/tj/Library/Caches/pypoetry/virtualenvs/adv-mla-at3-experimentation-iSAKc5_x-py3.12/lib/python3.12/site-packages (from lightgbm) (1.14.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 413\n",
      "[LightGBM] [Info] Number of data points in the train set: 4085281, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 324.383684\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "pipeline2 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lgbm', LGBMRegressor(learning_rate=0.001, num_leaves=50, max_depth=7)) \n",
    "])\n",
    "\n",
    "pipeline2.fit(X_train, y_train)\n",
    "\n",
    "y_preds2 = pipeline2.predict(X_train)\n",
    "y_val_preds2 = pipeline2.predict(X_val)\n",
    "y_test_preds2 = pipeline2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training: 143.7091744298257\n",
      "MAE Training: 104.79239795799226\n",
      "RMSE Validation: 142.82371710025612\n",
      "MAE Validation: 104.76881100929674\n",
      "RMSE Testing: 143.49196418856522\n",
      "MAE Testing: 104.8158550812793\n"
     ]
    }
   ],
   "source": [
    "print_regressor_scores(y_preds2, y_train, set_name='Training')\n",
    "print_regressor_scores(y_val_preds2, y_actuals=y_val, set_name='Validation')\n",
    "print_regressor_scores(y_test_preds2, y_actuals=y_test, set_name='Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "pipeline3 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('SGD', SGDRegressor(learning_rate='optimal',alpha=0.1)) \n",
    "])\n",
    "\n",
    "pipeline3.fit(X_train, y_train)\n",
    "\n",
    "y_preds3 = pipeline3.predict(X_train)\n",
    "y_val_preds3 = pipeline3.predict(X_val)\n",
    "y_test_preds3 = pipeline3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training: 663988798.303233\n",
      "MAE Training: 527912128.62180895\n",
      "RMSE Validation: 663994738.175438\n",
      "MAE Validation: 528064419.2527296\n",
      "RMSE Testing: 664383560.1067221\n",
      "MAE Testing: 528123134.92055064\n"
     ]
    }
   ],
   "source": [
    "# 3. SGDRegressor result\n",
    "\n",
    "print_regressor_scores(y_preds3, y_train, set_name='Training')\n",
    "print_regressor_scores(y_val_preds3, y_actuals=y_val, set_name='Validation')\n",
    "print_regressor_scores(y_test_preds3, y_actuals=y_test, set_name='Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_sgd = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('SGD', SGDRegressor(\n",
    "        learning_rate='invscaling',  \n",
    "        eta0=0.001,  \n",
    "        max_iter=1000,  \n",
    "        tol=1e-4  \n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline_sgd.fit(X_train, y_train)\n",
    "\n",
    "y_preds3 = pipeline_sgd.predict(X_train)\n",
    "y_val_preds3 = pipeline_sgd.predict(X_val)\n",
    "y_test_preds3 = pipeline_sgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training: 136.7813937479851\n",
      "MAE Training: 96.24451014140384\n",
      "RMSE Validation: 135.9198738981014\n",
      "MAE Validation: 96.18253896091979\n",
      "RMSE Testing: 136.51112215924726\n",
      "MAE Testing: 96.27562736429101\n"
     ]
    }
   ],
   "source": [
    "# 3. SGDRegressor result\n",
    "\n",
    "print_regressor_scores(y_preds3, y_train, set_name='Training')\n",
    "print_regressor_scores(y_val_preds3, y_actuals=y_val, set_name='Validation')\n",
    "print_regressor_scores(y_test_preds3, y_actuals=y_test, set_name='Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "pipeline4 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('Ada', AdaBoostRegressor()) \n",
    "])\n",
    "\n",
    "pipeline4.fit(X_train, y_train)\n",
    "\n",
    "y_preds3 = pipeline4.predict(X_train)\n",
    "y_val_preds3 = pipeline4.predict(X_val)\n",
    "y_test_preds3 = pipeline4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training: 239.69478899890268\n",
      "MAE Training: 192.6699526841691\n",
      "RMSE Validation: 239.48726029444512\n",
      "MAE Validation: 192.60243057179738\n",
      "RMSE Testing: 239.75430269125368\n",
      "MAE Testing: 192.68703559240902\n"
     ]
    }
   ],
   "source": [
    "print_regressor_scores(y_preds3, y_train, set_name='Training')\n",
    "print_regressor_scores(y_val_preds3, y_actuals=y_val, set_name='Validation')\n",
    "print_regressor_scores(y_test_preds3, y_actuals=y_test, set_name='Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "pipeline_rf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('random_forest', RandomForestRegressor(\n",
    "        n_estimators=20,\n",
    "        max_depth=5,\n",
    "        max_features='log2',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "\n",
    "y_preds5 = pipeline_rf.predict(X_train)\n",
    "y_val_preds5 = pipeline_rf.predict(X_val)\n",
    "y_test_preds5 = pipeline_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training: 153.66209223155462\n",
      "MAE Training: 110.71380431801786\n",
      "RMSE Validation: 152.62209640108296\n",
      "MAE Validation: 110.6031855614612\n",
      "RMSE Testing: 153.5224195293117\n",
      "MAE Testing: 110.76359140367751\n"
     ]
    }
   ],
   "source": [
    "print_regressor_scores(y_preds5, y_train, set_name='Training')\n",
    "print_regressor_scores(y_val_preds5, y_actuals=y_val, set_name='Validation')\n",
    "print_regressor_scores(y_test_preds5, y_actuals=y_test, set_name='Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "pipeline_rf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('random_forest', RandomForestRegressor(\n",
    "        n_estimators=20,\n",
    "        max_depth=5,\n",
    "        max_features='sqrt',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "\n",
    "y_preds5 = pipeline_rf.predict(X_train)\n",
    "y_val_preds5 = pipeline_rf.predict(X_val)\n",
    "y_test_preds5 = pipeline_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training: 148.66311192808527\n",
      "MAE Training: 106.95499720718799\n",
      "RMSE Validation: 147.63094347906735\n",
      "MAE Validation: 106.86490898985168\n",
      "RMSE Testing: 148.62350695127662\n",
      "MAE Testing: 107.0206381875522\n"
     ]
    }
   ],
   "source": [
    "print_regressor_scores(y_preds5, y_train, set_name='Training')\n",
    "print_regressor_scores(y_val_preds5, y_actuals=y_val, set_name='Validation')\n",
    "print_regressor_scores(y_test_preds5, y_actuals=y_test, set_name='Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "pipeline_rf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('random_forest', RandomForestRegressor(\n",
    "        n_estimators=50,\n",
    "        max_depth=5,\n",
    "        max_features='sqrt',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipeline_rf.fit(X_train, y_train)\n",
    "\n",
    "y_preds5 = pipeline_rf.predict(X_train)\n",
    "y_val_preds5 = pipeline_rf.predict(X_val)\n",
    "y_test_preds5 = pipeline_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training: 147.3470493157371\n",
      "MAE Training: 105.14035042981885\n",
      "RMSE Validation: 146.3135251874094\n",
      "MAE Validation: 105.06231659574148\n",
      "RMSE Testing: 147.31635763754997\n",
      "MAE Testing: 105.20337972359265\n"
     ]
    }
   ],
   "source": [
    "print_regressor_scores(y_preds5, y_train, set_name='Training')\n",
    "print_regressor_scores(y_val_preds5, y_actuals=y_val, set_name='Validation')\n",
    "print_regressor_scores(y_test_preds5, y_actuals=y_test, set_name='Testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose linear regression, make performances better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic_model = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
    "\n",
    "pipeline_ela = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('elastic', ElasticNet(alpha=1.0, l1_ratio=0.5)) \n",
    "])\n",
    "\n",
    "pipeline_ela.fit(X_train, y_train)\n",
    "\n",
    "y_preds6 = pipeline_ela.predict(X_train)\n",
    "y_val_preds6 = pipeline_ela.predict(X_val)\n",
    "y_test_preds6 = pipeline_ela.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training: 161.54868516178252\n",
      "MAE Training: 108.85429637746299\n",
      "RMSE Validation: 160.2458962104936\n",
      "MAE Validation: 108.76579881143603\n",
      "RMSE Testing: 161.8102993976421\n",
      "MAE Testing: 108.94793961291643\n"
     ]
    }
   ],
   "source": [
    "print_regressor_scores(y_preds6, y_train, set_name='Training')\n",
    "print_regressor_scores(y_val_preds6, y_actuals=y_val, set_name='Validation')\n",
    "print_regressor_scores(y_test_preds6, y_actuals=y_test, set_name='Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pipeline_poly = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('polynomial_features', PolynomialFeatures(degree=2)),  # Add polynomial features\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "pipeline_poly.fit(X_train, y_train)\n",
    "\n",
    "y_preds6 = pipeline_poly.predict(X_train)\n",
    "y_val_preds6 = pipeline_poly.predict(X_val)\n",
    "y_test_preds6 = pipeline_poly.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training: 126.53116727149795\n",
      "MAE Training: 88.94387358432162\n",
      "RMSE Validation: 125.68721603026289\n",
      "MAE Validation: 88.86830659525043\n",
      "RMSE Testing: 126.13707848658244\n",
      "MAE Testing: 88.96173089218289\n"
     ]
    }
   ],
   "source": [
    "print_regressor_scores(y_preds6, y_train, set_name='Training')\n",
    "print_regressor_scores(y_val_preds6, y_actuals=y_val, set_name='Validation')\n",
    "print_regressor_scores(y_test_preds6, y_actuals=y_test, set_name='Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "pipeline_ridge = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('polynomial_features', PolynomialFeatures(degree=2)),  # Add polynomial features\n",
    "    ('regressor', Ridge(alpha=0.01))\n",
    "])\n",
    "\n",
    "\n",
    "pipeline_ridge.fit(X_train, y_train)\n",
    "\n",
    "y_preds6 = pipeline_ridge.predict(X_train)\n",
    "y_val_preds6 = pipeline_ridge.predict(X_val)\n",
    "y_test_preds6 = pipeline_ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training: 126.53138591013736\n",
      "MAE Training: 88.94318428414516\n",
      "RMSE Validation: 125.68718968060071\n",
      "MAE Validation: 88.86738462926364\n",
      "RMSE Testing: 126.13731044947077\n",
      "MAE Testing: 88.96105398001401\n"
     ]
    }
   ],
   "source": [
    "print_regressor_scores(y_preds6, y_train, set_name='Training')\n",
    "print_regressor_scores(y_val_preds6, y_actuals=y_val, set_name='Validation')\n",
    "print_regressor_scores(y_test_preds6, y_actuals=y_test, set_name='Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv-mla-at3-experimentation-iSAKc5_x-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
