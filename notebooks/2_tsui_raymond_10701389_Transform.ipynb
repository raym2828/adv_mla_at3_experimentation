{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Loader\n",
    "2. Merge CSV into one master\n",
    "3. Remove to return the cheapest flight??\n",
    "4. Clean Data\n",
    "5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile \n",
    "import io\n",
    "import os\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import time\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to unzip folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted ../data/external/itineraries_csv.zip to ../data/interim\n"
     ]
    }
   ],
   "source": [
    "# Extract the zip and save in interim\n",
    "data_folder = '../data'\n",
    "zip_flight_data= data_folder + '/external/itineraries_csv.zip'\n",
    "\n",
    "extract_directory = data_folder +'/interim'\n",
    "\n",
    "# Read the zip file\n",
    "with zipfile.ZipFile(zip_flight_data, 'r') as z:\n",
    "    z.extractall(extract_directory)\n",
    "\n",
    "print(f\"Extracted {zip_flight_data} to {extract_directory}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to unzip CSV and save them as 1 per airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Use multiprocessing.Pool to run the folder processing function in parallel\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m multiprocessing\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39mmax_threads) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 24\u001b[0m     \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     27\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CHAMPION FILE EXTRACTOR\n",
    "def process_folder(folder):    \n",
    "    df_list = []\n",
    "    files = os.listdir(f\"../data/interim/itineraries_csv/{folder}\")\n",
    "    for file in files:\n",
    "        file_path = f\"../data/interim/itineraries_csv/{folder}/{file}\"\n",
    "        if file.endswith('.zip'):\n",
    "            df=pd.read_csv(file_path, compression='zip')\n",
    "            df_list.append(df)\n",
    "    df_list = pd.concat(df_list)\n",
    "    df_list.to_csv(f\"../data/interim/{folder}.csv\", index=False)\n",
    "    print(f\"Saved {folder}.csv\")\n",
    "root_dir = \"../data/interim/itineraries_csv\"\n",
    "folders = [entry.name for entry in os.scandir(root_dir) if entry.is_dir()]\n",
    "\n",
    "# Measure execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Limit the number of threads\n",
    "max_threads = 4\n",
    "\n",
    "# Use multiprocessing.Pool to run the folder processing function in parallel\n",
    "with multiprocessing.Pool(processes=max_threads) as pool:\n",
    "    pool.map(process_folder, folders)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Execution time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed folders\n"
     ]
    }
   ],
   "source": [
    "# Remove the processed folders to save storage space\n",
    "subprocess.run(f\"rm -rf ../data/interim/itineraries_csv\", shell=True)\n",
    "subprocess.run(f\"rm -rf ../data/interim/__MACOSX\", shell=True)\n",
    "print(\"Removed folders\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and convert the data\n",
    "def clean_data(df):\n",
    "\n",
    "    # Convert date columns\n",
    "    date_columns = ['searchDate', 'flightDate']\n",
    "    df[date_columns] = df[date_columns].apply(pd.to_datetime)\n",
    "\n",
    "    # Downcast float columns\n",
    "    float_columns = ['totalFare','totalTravelDistance']\n",
    "    for col in float_columns:\n",
    "        df[col] = pd.to_numeric(df[col],errors='coerce').astype('float32')\n",
    "\n",
    "    # Drop columns\n",
    "    drop_columns = ['legId', 'traveDuration','segmentsDepartureTimeEpochSeconds', 'segmentsArrivalTimeEpochSeconds','segmentsArrivalTimeRaw', 'segmentsDepartureAirportCode','segmentsAirlineCode','segmentsEquipmentDescription','segmentsDurationInSeconds', 'segmentsDistance']\n",
    "    return df\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the segment data into new variables\n",
    "\n",
    "airports = ['ATL', 'BOS', 'DEN', 'DFW', 'EWR', 'JFK', 'LAX', 'LGA', 'MIA', 'OAK', 'ORD', 'PHL', 'SFO']\n",
    "# Dictionary for the correct time offsets\n",
    "time_offsets = {'ATL': '-04:00', 'BOS': '-04:00', 'DEN': '-06:00', 'DFW': '-05:00', 'EWR': '-04:00', 'JFK': '-04:00', 'LAX': '-07:00', 'LGA': '-04:00', 'MIA': '-04:00', 'OAK': '-07:00', 'ORD': '-05:00', 'PHL': '-04:00', 'SFO': '-07:00'}\n",
    "\n",
    "# Remove row with more than 2 segments\n",
    "def process_segments_stops(df):\n",
    "    # Create boolean filter\n",
    "    filter = df[\"segmentsCabinCode\"].str.count(\"\\\\|\\\\|\") <= 1\n",
    "    df = df[filter]\n",
    "    return df\n",
    "\n",
    "# Departure Hour Processing\n",
    "def process_segments_DepartTime(df):\n",
    "    # Split the departure time\n",
    "    print(\"Shape before processing: \", df.shape)\n",
    "    df[\"segmentsDepartureTimeRaw_hour\"] = df[\"segmentsDepartureTimeRaw\"].str.split(\"|\").str[0]\n",
    "    airportcode = df[\"startingAirport\"].iloc[0]\n",
    "    correct_time_offset = time_offsets[airportcode]\n",
    "\n",
    "    # Filter for departure time hour that has the correct time offset\n",
    "    df = df[df[\"segmentsDepartureTimeRaw_hour\"].str[-6:] == correct_time_offset]\n",
    "    print(\"Shape after processing departure time: \", df.shape)\n",
    "\n",
    "    # Check date difference between the segmentsDepartureTimeRaw_hour and flight date and eliminate any that don't match\n",
    "    df[\"segmentsDepartureTimeRaw_hour\"] = pd.to_datetime(df[\"segmentsDepartureTimeRaw_hour\"]).dt.tz_localize(None)\n",
    "    df = df[(df[\"segmentsDepartureTimeRaw_hour\"] - df[\"flightDate\"]).dt.days == 0]\n",
    "    print(\"Shape after filtering segment departure not the same as flight date: \", df.shape)\n",
    "\n",
    "    # Extract out the hour of the day\n",
    "    df[\"DepartureTimeHour\"] = df[\"segmentsDepartureTimeRaw_hour\"].dt.hour.astype(\"uint8\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Cabin Class Encoding\n",
    "cabin_class_encoding = {\n",
    "    \"coach\": 1,\n",
    "    \"premium coach\": 2,\n",
    "    \"business\": 3,\n",
    "    \"first\": 4,\n",
    "}\n",
    "\n",
    "def process_segments_CabinClass(df):\n",
    "    # Split the Cabin class\n",
    "    df[\"CabinCode\"] = df[\"segmentsCabinCode\"].str.split(\"\\\\|\\\\|\")\n",
    "    \n",
    "    # Apply cabin_class_encoding on the cabin class\n",
    "    df[\"CabinCode\"] = df[\"CabinCode\"].apply(lambda x: [cabin_class_encoding.get(i, 0) for i in x])\n",
    "\n",
    "    # Get the average of the cabin class\n",
    "    df[\"CabinCode\"] = df[\"CabinCode\"].apply(lambda x: np.mean(x) if isinstance(x, list) else x).astype(\"float32\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Airline Name Processing\n",
    "\n",
    "# Airline Encoding \n",
    "# 1: Ultra Low Cost, 2: Budget, 3: Regional, 4: Full Service\n",
    "airline_type_encoding = {\n",
    "    'JetBlue Airways': 2,\n",
    "    'Sun Country Airlines': 2,\n",
    "    'United': 4,\n",
    "    'Delta': 4,\n",
    "    'Key Lime Air': 3,\n",
    "    'Boutique Air': 3,\n",
    "    'Contour Airlines': 3,\n",
    "    'Spirit Airlines': 1,\n",
    "    'American Airlines': 4,\n",
    "    'Alaska Airlines': 4,\n",
    "    'Southern Airways Express': 3,\n",
    "    'Frontier Airlines': 1,\n",
    "    'Hawaiian Airlines': 4,\n",
    "    'Cape Air': 3\n",
    "}\n",
    "\n",
    "# Airline Category Mapping\n",
    "def process_segments_AirlineNameScore(df):\n",
    "    df[\"AirlineNameScore\"] = df[\"segmentsAirlineName\"].str.split(\"\\\\|\\\\|\")\n",
    "    df[\"AirlineNameScore\"] = df[\"AirlineNameScore\"].apply(lambda x: [airline_type_encoding.get(i, 0) for i in x])\n",
    "    df[\"AirlineNameScore\"] = df[\"AirlineNameScore\"].apply(lambda x: np.max(x) if isinstance(x, list) else x).astype(\"uint8\") \n",
    "    return df\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_difference_columns(df):\n",
    "    # Calculate the difference in days\n",
    "    df['date_diff_days'] = (df[\"flightDate\"] - df[\"searchDate\"]).dt.days.astype('uint16')\n",
    "\n",
    "    # Calculate sin, cos to train cyclical patterns\n",
    "    # Day of the week\n",
    "    df['weekday'] = df[\"flightDate\"].dt.weekday.astype('uint8')\n",
    "    # df['weekday_sin'] = np.sin(2 * np.pi * df['weekday'] / 7).astype('float32')\n",
    "    # df['weekday_cos'] = np.cos(2 * np.pi * df['weekday'] / 7).astype('float32')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep only the useful columns and cheapest flight rows\n",
    "!!!!!!!!!!!!!MAKE SURE YOU UPDATE IF NEW VARIBLES CREATED!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_columns=['searchDate', 'flightDate', 'startingAirport', 'destinationAirport', 'isNonStop', 'isRefundable', 'isBasicEconomy', 'totalFare', 'totalTravelDistance', 'segmentsArrivalAirportCode','DepartureTimeHour', 'CabinCode', 'AirlineNameScore', 'date_diff_days', 'weekday' ] #'weekday_sin', 'weekday_cos'\n",
    "def keep_essential_columns(df):\n",
    "    return df[keep_columns]\n",
    "\n",
    "# Keep cheapess flight\n",
    "# Remove row so only the cheapest for the feature set is kept\n",
    "features_column = ['searchDate', 'flightDate', 'startingAirport', 'destinationAirport', 'isNonStop', 'isRefundable', 'isBasicEconomy','DepartureTimeHour', 'CabinCode', 'AirlineNameScore', 'date_diff_days']\n",
    "\n",
    "def keep_cheapest_flight(df):\n",
    "    df = df.sort_values('totalFare').drop_duplicates(features_column).sort_index()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/interim/SFO.csv')\n",
    "# df_clean = clean_data(df)\n",
    "\n",
    "# df_clean = process_segments_stops(df_clean)\n",
    "\n",
    "# df_cheapest = process_data(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df):\n",
    "    df = clean_data(df)\n",
    "    df = process_segments_stops(df)\n",
    "    df = process_segments_DepartTime(df)\n",
    "    df = process_segments_CabinClass(df)\n",
    "    df = process_segments_AirlineNameScore(df)\n",
    "    df = add_time_difference_columns(df)\n",
    "    df = keep_essential_columns(df)\n",
    "    df = keep_cheapest_flight(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before processing:  (871561, 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_222478/203945261.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"segmentsDepartureTimeRaw_hour\"] = df[\"segmentsDepartureTimeRaw\"].str.split(\"|\").str[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after processing departure time:  (871561, 24)\n",
      "Shape after filtering segment departure not the same as flight date:  (871561, 24)\n"
     ]
    }
   ],
   "source": [
    "df_processed=process_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 494381 entries, 0 to 949045\n",
      "Data columns (total 15 columns):\n",
      " #   Column                      Non-Null Count   Dtype         \n",
      "---  ------                      --------------   -----         \n",
      " 0   searchDate                  494381 non-null  datetime64[ns]\n",
      " 1   flightDate                  494381 non-null  datetime64[ns]\n",
      " 2   startingAirport             494381 non-null  object        \n",
      " 3   destinationAirport          494381 non-null  object        \n",
      " 4   isNonStop                   494381 non-null  bool          \n",
      " 5   isRefundable                494381 non-null  bool          \n",
      " 6   isBasicEconomy              494381 non-null  bool          \n",
      " 7   totalFare                   494381 non-null  float32       \n",
      " 8   totalTravelDistance         490401 non-null  float32       \n",
      " 9   segmentsArrivalAirportCode  494381 non-null  object        \n",
      " 10  DepartureTimeHour           494381 non-null  uint8         \n",
      " 11  CabinCode                   494381 non-null  float32       \n",
      " 12  AirlineNameScore            494381 non-null  uint8         \n",
      " 13  date_diff_days              494381 non-null  uint16        \n",
      " 14  weekday                     494381 non-null  uint8         \n",
      "dtypes: bool(3), datetime64[ns](2), float32(3), object(3), uint16(1), uint8(3)\n",
      "memory usage: 32.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 874055 entries, 0 to 874068\n",
      "Data columns (total 30 columns):\n",
      " #   Column                             Non-Null Count   Dtype         \n",
      "---  ------                             --------------   -----         \n",
      " 0   legId                              874055 non-null  object        \n",
      " 1   searchDate                         874055 non-null  datetime64[ns]\n",
      " 2   flightDate                         874055 non-null  datetime64[ns]\n",
      " 3   startingAirport                    874055 non-null  object        \n",
      " 4   destinationAirport                 874055 non-null  object        \n",
      " 5   travelDuration                     874055 non-null  object        \n",
      " 6   isBasicEconomy                     874055 non-null  bool          \n",
      " 7   isRefundable                       874055 non-null  bool          \n",
      " 8   isNonStop                          874055 non-null  bool          \n",
      " 9   totalFare                          874055 non-null  float32       \n",
      " 10  totalTravelDistance                769021 non-null  float64       \n",
      " 11  segmentsDepartureTimeEpochSeconds  874055 non-null  object        \n",
      " 12  segmentsDepartureTimeRaw           874055 non-null  object        \n",
      " 13  segmentsArrivalTimeEpochSeconds    874055 non-null  object        \n",
      " 14  segmentsArrivalTimeRaw             874055 non-null  object        \n",
      " 15  segmentsArrivalAirportCode         874055 non-null  object        \n",
      " 16  segmentsDepartureAirportCode       874055 non-null  object        \n",
      " 17  segmentsAirlineName                874055 non-null  object        \n",
      " 18  segmentsAirlineCode                874055 non-null  object        \n",
      " 19  segmentsEquipmentDescription       848468 non-null  object        \n",
      " 20  segmentsDurationInSeconds          874055 non-null  object        \n",
      " 21  segmentsDistance                   856841 non-null  object        \n",
      " 22  segmentsCabinCode                  874055 non-null  object        \n",
      " 23  segmentsDepartureTimeRaw_hour      874055 non-null  int8          \n",
      " 24  CabinCode                          874055 non-null  float64       \n",
      " 25  AirlineNameScore                   874055 non-null  int64         \n",
      " 26  date_diff_days                     874055 non-null  int64         \n",
      " 27  weekday                            874055 non-null  int32         \n",
      " 28  weekday_sin                        874055 non-null  float64       \n",
      " 29  weekday_cos                        874055 non-null  float64       \n",
      "dtypes: bool(3), datetime64[ns](2), float32(1), float64(4), int32(1), int64(2), int8(1), object(16)\n",
      "memory usage: 176.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge into one master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = process_data(df)\n",
    "    return df\n",
    "\n",
    "def process_and_combine_csv_parallel(directory, airports, max_workers=6):\n",
    "    start_time = time.time()\n",
    "    master_df = pd.DataFrame()\n",
    "    file_paths = [os.path.join(directory, f'{airport}.csv') for airport in airports if os.path.exists(os.path.join(directory, f'{airport}.csv'))]\n",
    "    # Option 1: Use concurrent.futures.ProcessPoolExecutor\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = executor.map(process_csv, file_paths)\n",
    "    \n",
    "    for df in results:\n",
    "        master_df = pd.concat([master_df, df], ignore_index=True)\n",
    "    \n",
    "    # # Option 2: Use multiprocessing.Pool\n",
    "    # with multiprocessing.Pool(processes=6) as pool:\n",
    "    #     results = pool.map(process_csv, file_paths)\n",
    "    \n",
    "    # for df in results:\n",
    "    #     master_df = pd.concat([master_df, df], ignore_index=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Execution time: {end_time - start_time:.2f} seconds\")\n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before processing:  (647768, 23)\n",
      "Shape before processing:  (685158, 23)\n",
      "Shape before processing:  (749151, 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228931/203945261.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"segmentsDepartureTimeRaw_hour\"] = df[\"segmentsDepartureTimeRaw\"].str.split(\"|\").str[0]\n",
      "/tmp/ipykernel_228931/203945261.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"segmentsDepartureTimeRaw_hour\"] = df[\"segmentsDepartureTimeRaw\"].str.split(\"|\").str[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before processing:  (850459, 23)\n",
      "Shape before processing:  (828482, 23)\n",
      "Shape after processing departure time:  (647768, 24)\n",
      "Shape after processing departure time:  (685158, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228931/203945261.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"segmentsDepartureTimeRaw_hour\"] = df[\"segmentsDepartureTimeRaw\"].str.split(\"|\").str[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before processing:  (958591, 23)\n",
      "Shape after filtering segment departure not the same as flight date:  (647768, 24)\n",
      "Shape after filtering segment departure not the same as flight date:  (685158, 24)\n",
      "Shape after processing departure time:  (749151, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228931/203945261.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"segmentsDepartureTimeRaw_hour\"] = df[\"segmentsDepartureTimeRaw\"].str.split(\"|\").str[0]\n",
      "/tmp/ipykernel_228931/203945261.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"segmentsDepartureTimeRaw_hour\"] = df[\"segmentsDepartureTimeRaw\"].str.split(\"|\").str[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after filtering segment departure not the same as flight date:  (749151, 24)\n",
      "Shape after processing departure time:  (850455, 24)\n",
      "Shape after processing departure time:  (828474, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228931/203945261.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"segmentsDepartureTimeRaw_hour\"] = df[\"segmentsDepartureTimeRaw\"].str.split(\"|\").str[0]\n",
      "/tmp/ipykernel_228931/203945261.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"segmentsDepartureTimeRaw_hour\"] = pd.to_datetime(df[\"segmentsDepartureTimeRaw_hour\"]).dt.tz_localize(None)\n",
      "/tmp/ipykernel_228931/203945261.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"segmentsDepartureTimeRaw_hour\"] = pd.to_datetime(df[\"segmentsDepartureTimeRaw_hour\"]).dt.tz_localize(None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after filtering segment departure not the same as flight date:  (828468, 24)\n",
      "Shape after processing departure time:  (958591, 24)\n",
      "Shape after filtering segment departure not the same as flight date:  (850455, 24)\n",
      "Shape after filtering segment departure not the same as flight date:  (958591, 24)\n",
      "Shape before processing: (920796, 23) \n",
      "Shape before processing:  (284847, 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228931/203945261.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"segmentsDepartureTimeRaw_hour\"] = df[\"segmentsDepartureTimeRaw\"].str.split(\"|\").str[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before processing:  (826262, 23)\n",
      "Shape after processing departure time:  (284766, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228931/203945261.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"segmentsDepartureTimeRaw_hour\"] = pd.to_datetime(df[\"segmentsDepartureTimeRaw_hour\"]).dt.tz_localize(None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after filtering segment departure not the same as flight date:  (284766, 24)\n",
      "Shape before processing:  (864568, 23)\n",
      "Shape before processing:  (1306695, 23)\n",
      "Shape before processing:  (734346, 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228931/203945261.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"segmentsDepartureTimeRaw_hour\"] = df[\"segmentsDepartureTimeRaw\"].str.split(\"|\").str[0]\n",
      "/tmp/ipykernel_228931/203945261.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"segmentsDepartureTimeRaw_hour\"] = df[\"segmentsDepartureTimeRaw\"].str.split(\"|\").str[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after processing departure time:  (920796, 24)\n",
      "Shape after filtering segment departure not the same as flight date:  (920796, 24)\n",
      "Shape after processing departure time:  (826259, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228931/203945261.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"segmentsDepartureTimeRaw_hour\"] = pd.to_datetime(df[\"segmentsDepartureTimeRaw_hour\"]).dt.tz_localize(None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after filtering segment departure not the same as flight date:  (826259, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228931/203945261.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"segmentsDepartureTimeRaw_hour\"] = df[\"segmentsDepartureTimeRaw\"].str.split(\"|\").str[0]\n",
      "/tmp/ipykernel_228931/203945261.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"segmentsDepartureTimeRaw_hour\"] = df[\"segmentsDepartureTimeRaw\"].str.split(\"|\").str[0]\n",
      "/tmp/ipykernel_228931/203945261.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"segmentsDepartureTimeRaw_hour\"] = df[\"segmentsDepartureTimeRaw\"].str.split(\"|\").str[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after processing departure time:  (1306695, 24)\n",
      "Shape after processing departure time:  (864568, 24)\n",
      "Shape after processing departure time:  (734346, 24)\n",
      "Shape after filtering segment departure not the same as flight date:  (1306695, 24)\n",
      "Shape after filtering segment departure not the same as flight date:  (864568, 24)\n",
      "Shape after filtering segment departure not the same as flight date:  (734346, 24)\n",
      "Shape before processing:  (871561, 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_228931/203945261.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"segmentsDepartureTimeRaw_hour\"] = df[\"segmentsDepartureTimeRaw\"].str.split(\"|\").str[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after processing departure time:  (871561, 24)\n",
      "Shape after filtering segment departure not the same as flight date:  (871561, 24)\n",
      "Execution time: 108.67 seconds\n"
     ]
    }
   ],
   "source": [
    "# 6 workers\n",
    "directory = '../data/interim'\n",
    "\n",
    "master_df = process_and_combine_csv_parallel(directory, airports, max_workers=6) # Adjust workers if sytem crashes due to memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target\n",
    "X = master_df.drop(['totalFare'], axis=1)\n",
    "y = master_df['totalFare']\n",
    "\n",
    "# Split data into 80:20 for training and testing\n",
    "train_data, test_data = train_test_split(master_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the data\n",
    "train_data.to_feather('../data/processed/train_data.feather')\n",
    "test_data.to_feather('../data/processed/test_data.feather')\n",
    "\n",
    "# # Open the data\n",
    "# pd.read_feather('../data/processed/train_data.feather')\n",
    "# pd.read_feather('../data/processed/test_data.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5287832 entries, 6164974 to 6413414\n",
      "Data columns (total 15 columns):\n",
      " #   Column                      Dtype         \n",
      "---  ------                      -----         \n",
      " 0   searchDate                  datetime64[ns]\n",
      " 1   flightDate                  datetime64[ns]\n",
      " 2   startingAirport             object        \n",
      " 3   destinationAirport          object        \n",
      " 4   isNonStop                   bool          \n",
      " 5   isRefundable                bool          \n",
      " 6   isBasicEconomy              bool          \n",
      " 7   totalFare                   float32       \n",
      " 8   totalTravelDistance         float32       \n",
      " 9   segmentsArrivalAirportCode  object        \n",
      " 10  DepartureTimeHour           uint8         \n",
      " 11  CabinCode                   float32       \n",
      " 12  AirlineNameScore            uint8         \n",
      " 13  date_diff_days              uint16        \n",
      " 14  weekday                     uint8         \n",
      "dtypes: bool(3), datetime64[ns](2), float32(3), object(3), uint16(1), uint8(3)\n",
      "memory usage: 342.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_df.to_feather('../data/processed/master.feather')\n",
    "# Open the feather file\n",
    "# df = pd.read_feather('../data/processed/master.feather')\n",
    "# df.info()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
