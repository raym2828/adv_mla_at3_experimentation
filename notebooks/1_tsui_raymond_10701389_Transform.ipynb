{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Loader\n",
    "2. Merge CSV into one master\n",
    "3. Remove to return the cheapest flight??\n",
    "3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile \n",
    "import io\n",
    "import os\n",
    "import concurrent.futures\n",
    "import time\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to unzip folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted ../data/external/itineraries_csv.zip to ../data/interim\n"
     ]
    }
   ],
   "source": [
    "# Extract the zip and save in interim\n",
    "data_folder = '../data'\n",
    "zip_flight_data= data_folder + '/external/itineraries_csv.zip'\n",
    "\n",
    "extract_directory = data_folder +'/interim'\n",
    "\n",
    "# Read the zip file\n",
    "with zipfile.ZipFile(zip_flight_data, 'r') as z:\n",
    "    z.extractall(extract_directory)\n",
    "\n",
    "print(f\"Extracted {zip_flight_data} to {extract_directory}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to unzip CSV and save them as 1 per airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved IAD.csv\n",
      "Saved JFK.csv\n",
      "Saved PHL.csv\n",
      "Saved ORD.csv\n",
      "Saved OAK.csv\n",
      "Saved DTW.csv\n",
      "Saved DEN.csv\n",
      "Saved LAX.csv\n",
      "Saved CLT.csv\n",
      "Saved EWR.csv\n",
      "Saved MIA.csv\n",
      "Saved BOS.csv\n",
      "Saved LGA.csv\n",
      "Saved ATL.csv\n",
      "Saved SFO.csv\n",
      "Saved DFW.csv\n",
      "Execution time: 56.55 seconds\n"
     ]
    }
   ],
   "source": [
    "# CHAMPION FILE EXTRACTOR\n",
    "def process_folder(folder):    \n",
    "    df_list = []\n",
    "    files = os.listdir(f\"../data/interim/itineraries_csv/{folder}\")\n",
    "    for file in files:\n",
    "        file_path = f\"../data/interim/itineraries_csv/{folder}/{file}\"\n",
    "        if file.endswith('.zip'):\n",
    "            df=pd.read_csv(file_path, compression='zip')\n",
    "            df_list.append(df)\n",
    "    df_list = pd.concat(df_list)\n",
    "    df_list.to_csv(f\"../data/interim/{folder}.csv\", index=False)\n",
    "    print(f\"Saved {folder}.csv\")\n",
    "root_dir = \"../data/interim/itineraries_csv\"\n",
    "folders = [entry.name for entry in os.scandir(root_dir) if entry.is_dir()]\n",
    "\n",
    "# Measure execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Limit the number of threads\n",
    "max_threads = 4\n",
    "\n",
    "# Use multiprocessing.Pool to run the folder processing function in parallel\n",
    "with multiprocessing.Pool(processes=max_threads) as pool:\n",
    "    pool.map(process_folder, folders)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Execution time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed folders\n"
     ]
    }
   ],
   "source": [
    "# Remove the processed folders to save storage space\n",
    "subprocess.run(f\"rm -rf ../data/interim/itineraries_csv\", shell=True)\n",
    "subprocess.run(f\"rm -rf ../data/interim/__MACOSX\", shell=True)\n",
    "print(\"Removed folders\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in airport CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/interim/ATL.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and convert the data\n",
    "def transform_data(df):\n",
    "\n",
    "    # Convert date columns\n",
    "    date_columns = ['searchDate', 'flightDate']\n",
    "    df[date_columns] = df[date_columns].apply(pd.to_datetime)\n",
    "\n",
    "    # Convert float to numeric\n",
    "    float_columns = ['totalFare','totalTravelDistance']\n",
    "    for col in float_columns:\n",
    "        df[col] = pd.to_numeric(df[col],errors='coerce').astype('float32')\n",
    "\n",
    "    # Drop rows\n",
    "    df = df.dropna(subset=['segmentsEquipmentDescription','segmentsAirlineName'])\n",
    "    return df\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covert the segment data into new variables\n",
    "\n",
    "airports= ['ATL','BOS','DEN','DFW','EWR','JFK','LAX','LGA','MIA','OAK','ORD','PHL','SFO']\n",
    "# dictionary for the correct time offsets\n",
    "time_offsets = {'ATL': '-04:00', 'BOS' : '-04:00' , 'DEN':'-06:00', 'DFW':'-05:00' ,'EWR':'-04:00',   'JFK': '-04:00','LAX': '-07:00', 'LGA': '-04:00', 'MIA': '-04:00', 'OAK': '-07:00', 'ORD': '-05:00', 'PHL': '-04:00', 'SFO': '-07:00'}\n",
    "\n",
    "# Departure Hour Processing\n",
    "def process_segments_DepartTime(df):\n",
    "    # Split the departure time\n",
    "    print(\"Shape before processing: \", df.shape)\n",
    "    df[\"segmentsDepartureTimeRaw_hour\"] = df[\"segmentsDepartureTimeRaw\"].str.split(\"|\").str[0]\n",
    "    airportcode = df[\"startingAirport\"][0]\n",
    "    correct_time_offset = time_offsets[airportcode]\n",
    "\n",
    "    # filter for departure time hour that has the correct time offset\n",
    "    df = df[df[\"segmentsDepartureTimeRaw_hour\"].str[-6:] == correct_time_offset]\n",
    "    print(\"Shape after processing departure time: \", df.shape)\n",
    "\n",
    "    # check date difference between the  segmentsDepartureTimeRaw_hour aNd flight date and eliminate any that dont match\n",
    "    df[\"segmentsDepartureTimeRaw_hour\"] = pd.to_datetime(\n",
    "        df[\"segmentsDepartureTimeRaw_hour\"]\n",
    "    ).dt.tz_localize(None)\n",
    "    df = df[(df[\"segmentsDepartureTimeRaw_hour\"] - df[\"flightDate\"]).dt.days == 0]\n",
    "    print(\"Shape after filtering segment departure not the same as flight date: \", df.shape)\n",
    "\n",
    "    # extract out the hour of the day\n",
    "    df[\"segmentsDepartureTimeRaw_hour\"] = df[\"segmentsDepartureTimeRaw_hour\"].dt.hour.astype(\"int8\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Cabin Class Encoding\n",
    "cabin_class_encoding = {\n",
    "    \"coach\": 1,\n",
    "    \"premium coach\": 2,\n",
    "    \"business\": 3,\n",
    "    \"first\": 4,\n",
    "}\n",
    "\n",
    "def process_segments_CabinClass(df):\n",
    "    # Split the Cabin class\n",
    "    df[\"CabinCode\"] = df[\"segmentsCabinCode\"].str.split(\"\\\\|\\\\|\")\n",
    "    \n",
    "    # apply cabin_class_encoding on the cabin class\n",
    "    df[\"CabinCode\"] = df[\"CabinCode\"].apply(lambda x: [cabin_class_encoding.get(i, 0) for i in x])\n",
    "\n",
    "    # get the average of the cabin class\n",
    "    df[\"CabinCode\"] = df[\"CabinCode\"].apply(lambda x: np.mean(x) if isinstance(x, list) else x)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Airline Name Processing\n",
    "\n",
    "# Airline Encoding \n",
    "# 1: Ultra Low Cost, 2: Budget, 3: Regional, 4: Full Service\n",
    "airline_type_encoding = {\n",
    "    'JetBlue Airways': 2,\n",
    "    'Sun Country Airlines': 2,\n",
    "    'United': 4,\n",
    "    'Delta': 4,\n",
    "    'Key Lime Air': 3,\n",
    "    'Boutique Air': 3,\n",
    "    'Contour Airlines': 3,\n",
    "    'Spirit Airlines': 1,\n",
    "    'American Airlines': 4,\n",
    "    'Alaska Airlines': 4,\n",
    "    'Southern Airways Express': 3,\n",
    "    'Frontier Airlines': 1,\n",
    "    'Hawaiian Airlines': 4,\n",
    "    'Cape Air': 3\n",
    "}\n",
    "\n",
    "# Airline Category Mapping\n",
    "def process_segments_AirlineNameScore(df):\n",
    "    df[\"AirlineNameScore\"] = df[\"segmentsAirlineName\"].str.split(\"\\\\|\\\\|\")\n",
    "    df[\"AirlineNameScore\"] = df[\"AirlineNameScore\"].apply(lambda x: [airline_type_encoding.get(i, 0) for i in x])\n",
    "    df[\"AirlineNameScore\"]= df[\"AirlineNameScore\"].apply(lambda x: np.max(x) if isinstance(x, list) else x) \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_difference_columns(df):\n",
    "    # Calculate the difference in days\n",
    "    df['date_diff_days'] = (df[\"flightDate\"] - df[\"searchDate\"]).dt.days\n",
    "\n",
    "    # Calculate sin, cos to train cyclical patterns\n",
    "    # Day of the week\n",
    "    df['weekday'] = df[\"flightDate\"].dt.weekday\n",
    "    df['weekday_sin'] = np.sin(2 * np.pi * df['weekday'] / 7)\n",
    "    df['weekday_cos'] = np.cos(2 * np.pi * df['weekday'] / 7)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge into one master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
